{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on GPU with vectorized mini-batch SGD\n",
    "\n",
    "This notebook is part of article [Explaining RNNs without neural networks](https://explained.ai/rnn/index.html) and notebook [prep.ipynb](prep.ipynb) should be run before this notebook as it needs files: `data/X.pkl` and `data/y.pkl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "!if ! test -f support.py; then wget https://raw.githubusercontent.com/parrt/ml-articles/master/rnn/notebooks/support.py; fi\n",
    "\n",
    "from support import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "with open('data/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TESTING SUBSAMPLE\n",
    "idx = list(np.random.randint(0,len(X),size=2000))\n",
    "X = np.array(X)[idx].tolist()\n",
    "y = np.array(y)[idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_matrix(X, max_len, vocab, verbose=False):\n",
    "    X_onehot = torch.zeros((len(X),max_len,len(vocab)), dtype=torch.float64)\n",
    "    for i,x in enumerate(X):\n",
    "        pad = max_len - len(x)\n",
    "        for j,c in enumerate(x):\n",
    "            X_onehot[i, j+pad, ctoi[c]] = 1\n",
    "        if verbose: print(x); print(X_onehot[i].T, \"\\n\")\n",
    "    return X_onehot.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X_onehot, max_len:int, vocab:dict):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "    H = torch.zeros(nhidden, len(X_onehot), device=device, dtype=torch.float64, requires_grad=False)\n",
    "    for j in range(max_len):\n",
    "        x_step_t = X_onehot[:,j].T\n",
    "        H = W.mm(H) + U.mm(x_step_t)\n",
    "        H = torch.tanh(H)        \n",
    "    o = V.mm(H)\n",
    "    o = o.T # make it batch_size x nclasses\n",
    "    o = softmax(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just some matrices. First, set up hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, dtype=torch.long) # keep these on the CPU\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ctoi = getvocab(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,500 training records, batch size 300, 29 features (chars), 18 target languages, state is 100-vector\n"
     ]
    }
   ],
   "source": [
    "nhidden = 100\n",
    "batch_size = 32\n",
    "\n",
    "n = len(X_train)\n",
    "\n",
    "nbatches = n // batch_size\n",
    "n = nbatches * batch_size\n",
    "X_train = X_train[0:n]\n",
    "y_train = y_train[0:n]\n",
    "vocab, ctoi = getvocab(X)\n",
    "max_len = get_max_len(X)\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(torch.unique(y_train))\n",
    "\n",
    "print(f\"{n:,d} training records, batch size {batch_size}, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using pure SGD, one record used to compute gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  3.4817 accur 0.545 | train loss  1.7416 accur 0.659 | valid loss  1.8261 accur 0.657\n",
      "Epoch:   2 accum loss  1.5075 accur 0.678 | train loss  1.2010 accur 0.718 | valid loss  1.3367 accur 0.698\n",
      "Epoch:   3 accum loss  1.1555 accur 0.724 | train loss  0.9943 accur 0.741 | valid loss  1.1665 accur 0.722\n",
      "Epoch:   4 accum loss  0.9850 accur 0.747 | train loss  0.8460 accur 0.772 | valid loss  1.0457 accur 0.735\n",
      "Epoch:   5 accum loss  0.8697 accur 0.772 | train loss  0.7676 accur 0.787 | valid loss  1.0029 accur 0.741\n",
      "Epoch:   6 accum loss  0.7833 accur 0.788 | train loss  0.7027 accur 0.801 | valid loss  0.9785 accur 0.741\n",
      "Epoch:   7 accum loss  0.7201 accur 0.800 | train loss  0.6471 accur 0.812 | valid loss  0.9578 accur 0.748\n",
      "Epoch:   8 accum loss  0.6710 accur 0.810 | train loss  0.6012 accur 0.824 | valid loss  0.9391 accur 0.756\n",
      "Epoch:   9 accum loss  0.6314 accur 0.815 | train loss  0.5626 accur 0.832 | valid loss  0.9253 accur 0.756\n",
      "Epoch:  10 accum loss  0.5983 accur 0.823 | train loss  0.5354 accur 0.837 | valid loss  0.9242 accur 0.760\n",
      "Epoch:  11 accum loss  0.5669 accur 0.829 | train loss  0.5054 accur 0.845 | valid loss  0.9232 accur 0.765\n",
      "Epoch:  12 accum loss  0.5371 accur 0.836 | train loss  0.4708 accur 0.854 | valid loss  0.9156 accur 0.765\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.42 s, sys: 44.4 ms, total: 3.46 s\n",
      "Wall time: 3.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden,    nhidden,   device=device, dtype=torch.float64, requires_grad=True)\n",
    "U = torch.randn(nhidden,  nfeatures, device=device, dtype=torch.float64, requires_grad=True) # embed one-hot char vec\n",
    "V = torch.randn(nclasses, nhidden,   device=device, dtype=torch.float64, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "# Let's compute the big 3D one hot matrix for all examples so we don't re-create\n",
    "# four batches all the time; might push data back and forth between CPU and GPU\n",
    "X_train_onehot = onehot_matrix(X_train, max_len, vocab)\n",
    "X_valid_onehot = onehot_matrix(X_valid, max_len, vocab)\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.005, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total = 0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        batch_X = X_train_onehot[p:p+batch_size]\n",
    "        batch_y = y_train[p:p+batch_size]\n",
    "        H = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)\n",
    "        for t in range(max_len):\n",
    "            x_step_t = batch_X[:,t].T # make it len(vocab) x batch_size\n",
    "            H = W.mm(H) + U.mm(x_step_t)\n",
    "            H = torch.tanh(H)\n",
    "        o = V.mm(H)\n",
    "        o = o.T # make it batch_size x nclasses\n",
    "        o = softmax(o)\n",
    "        loss = cross_entropy(o, batch_y)\n",
    "#         print(loss.item())\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==batch_y\n",
    "        epoch_training_accur += torch.sum(correct)\n",
    "        total += len(batch_y)\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    epoch_training_loss /= nbatches\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train_onehot, max_len, vocab)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_train\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid_onehot, max_len, vocab)\n",
    "        valid_loss = cross_entropy(o, y_valid).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_valid\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing on 80% training from full data set using a GeForce RTX 2080 Ti with 11G RAM.\n",
    "    \n",
    "```\n",
    "CPU times: user 24.2 s, sys: 1.12 s, total: 25.4 s\n",
    "Wall time: 25.3 s\n",
    "```\n",
    "\n",
    "Roughly the same speed as the vectorized running on the CPU, but our data set is pretty small and is likely dominated by all of the metrics I'm computing.  When I bump batch size to 300, I get a time of 3.5s vs 25s. Training accuracy is much better too as is validation. Hmm... LeCun and others report that validation error will suffer. Oh well. Bigger is better for this case.\n",
    "\n",
    "Ah. Figured out speed thing. The CPU-only version was using all my core! So, similar to GPU on this problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
