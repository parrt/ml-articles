{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on GPU with vectorized mini-batch SGD\n",
    "\n",
    "This notebook is part of article [Explaining RNNs without neural networks](https://explained.ai/rnn/index.html) and notebook [prep.ipynb](prep.ipynb) should be run before this notebook as it needs files: `data/X.pkl` and `data/y.pkl`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "!if ! test -f support.py; then wget https://raw.githubusercontent.com/parrt/ml-articles/master/rnn/notebooks/support.py; fi\n",
    "\n",
    "from support import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "with open('data/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TESTING SUBSAMPLE\n",
    "idx = list(np.random.randint(0,len(X),size=2000))\n",
    "X = np.array(X)[idx].tolist()\n",
    "y = np.array(y)[idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_matrix(X, max_len, vocab, verbose=False):\n",
    "    X_onehot = torch.zeros((len(X),max_len,len(vocab)), dtype=torch.float64)\n",
    "    for i,x in enumerate(X):\n",
    "        pad = max_len - len(x)\n",
    "        for j,c in enumerate(x):\n",
    "            X_onehot[i, j+pad, ctoi[c]] = 1\n",
    "        if verbose: print(x); print(X_onehot[i].T, \"\\n\")\n",
    "    return X_onehot.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X_onehot, max_len:int, vocab:dict):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "    H = torch.zeros(nhidden, len(X_onehot), device=device, dtype=torch.float64, requires_grad=False)\n",
    "    for j in range(max_len):\n",
    "        x_step_t = X_onehot[:,j].T\n",
    "        H = W.mm(H) + U.mm(x_step_t)\n",
    "        H = torch.tanh(H)        \n",
    "    o = V.mm(H)\n",
    "    o = o.T # make it batch_size x nclasses\n",
    "    o = softmax(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just some matrices. First, set up hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, dtype=torch.long) # keep these on the CPU\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ctoi = getvocab(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,688 training records, batch size 32, 29 features (chars), 18 target languages, state is 100-vector\n"
     ]
    }
   ],
   "source": [
    "nhidden = 100\n",
    "batch_size = 32\n",
    "\n",
    "n = len(X_train)\n",
    "\n",
    "nbatches = n // batch_size\n",
    "n = nbatches * batch_size\n",
    "X_train = X_train[0:n]\n",
    "y_train = y_train[0:n]\n",
    "vocab, ctoi = getvocab(X)\n",
    "max_len = get_max_len(X)\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(torch.unique(y_train))\n",
    "\n",
    "print(f\"{n:,d} training records, batch size {batch_size}, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using pure SGD, one record used to compute gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  1.9714 accur 0.597 | train loss  1.1566 accur 0.674 | valid loss  1.3000 accur 0.655\n",
      "Epoch:   2 accum loss  1.1729 accur 0.673 | train loss  0.9960 accur 0.697 | valid loss  1.1791 accur 0.666\n",
      "Epoch:   3 accum loss  1.0144 accur 0.714 | train loss  0.9353 accur 0.733 | valid loss  1.1374 accur 0.707\n",
      "Epoch:   4 accum loss  0.9206 accur 0.735 | train loss  0.8983 accur 0.740 | valid loss  1.1109 accur 0.700\n",
      "Epoch:   5 accum loss  0.8785 accur 0.740 | train loss  0.8887 accur 0.734 | valid loss  1.1108 accur 0.693\n",
      "Epoch:   6 accum loss  0.8275 accur 0.755 | train loss  0.7861 accur 0.768 | valid loss  1.0469 accur 0.721\n",
      "Epoch:   7 accum loss  0.8172 accur 0.759 | train loss  0.7643 accur 0.770 | valid loss  1.0405 accur 0.722\n",
      "Epoch:   8 accum loss  0.7823 accur 0.769 | train loss  0.8170 accur 0.751 | valid loss  1.1112 accur 0.704\n",
      "Epoch:   9 accum loss  0.7583 accur 0.773 | train loss  0.7415 accur 0.783 | valid loss  1.0672 accur 0.735\n",
      "Epoch:  10 accum loss  0.7416 accur 0.775 | train loss  0.6878 accur 0.788 | valid loss  0.9992 accur 0.737\n",
      "Epoch:  11 accum loss  0.7328 accur 0.781 | train loss  0.6759 accur 0.792 | valid loss  0.9836 accur 0.746\n",
      "Epoch:  12 accum loss  0.7149 accur 0.785 | train loss  0.6813 accur 0.785 | valid loss  1.0275 accur 0.738\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.8 s, sys: 1.47 s, total: 24.3 s\n",
      "Wall time: 20.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden,    nhidden,   device=device, dtype=torch.float64, requires_grad=True)\n",
    "U = torch.randn(nhidden,  nfeatures, device=device, dtype=torch.float64, requires_grad=True) # embed one-hot char vec\n",
    "V = torch.randn(nclasses, nhidden,   device=device, dtype=torch.float64, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "# Let's compute the big 3D one hot matrix for all examples so we don't re-create\n",
    "# four batches all the time; might push data back and forth between CPU and GPU\n",
    "X_train_onehot = onehot_matrix(X_train, max_len, vocab)\n",
    "X_valid_onehot = onehot_matrix(X_valid, max_len, vocab)\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.005, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total = 0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        batch_X = X_train_onehot[p:p+batch_size]\n",
    "        batch_y = y_train[p:p+batch_size]\n",
    "        H = torch.zeros(nhidden, batch_size, device=device, dtype=torch.float64, requires_grad=False)\n",
    "        for t in range(max_len):\n",
    "            x_step_t = batch_X[:,t].T # make it len(vocab) x batch_size\n",
    "            H = W.mm(H) + U.mm(x_step_t)\n",
    "            H = torch.tanh(H)\n",
    "        o = V.mm(H)\n",
    "        o = o.T # make it batch_size x nclasses\n",
    "        o = softmax(o)\n",
    "        loss = cross_entropy(o, batch_y)\n",
    "#         print(loss.item())\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==batch_y\n",
    "        epoch_training_accur += torch.sum(correct)\n",
    "        total += len(batch_y)\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    epoch_training_loss /= nbatches\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train_onehot, max_len, vocab)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_train\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid_onehot, max_len, vocab)\n",
    "        valid_loss = cross_entropy(o, y_valid).item()\n",
    "        correct = torch.argmax(o, dim=1).detach().cpu()==y_valid\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing on 80% training from full data set using a GeForce RTX 2080 Ti with 11G RAM.\n",
    "    \n",
    "```\n",
    "CPU times: user 24.2 s, sys: 1.12 s, total: 25.4 s\n",
    "Wall time: 25.3 s\n",
    "```\n",
    "\n",
    "Roughly the same speed as the vectorized running on the CPU, but our data set is pretty small and is likely dominated by all of the metrics I'm computing.  When I bump batch size to 300, I get a time of 3.5s vs 25s. Training accuracy is much better too as is validation. Hmm... LeCun and others report that validation error will suffer. Oh well. Bigger is better for this case.\n",
    "\n",
    "Ah. Figured out speed thing. The CPU-only version was using all my core! So, similar to GPU on this problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
