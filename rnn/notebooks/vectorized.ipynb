{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using vectorized mini-batch SGD\n",
    "\n",
    "This notebook is part of article [Explaining RNNs without neural networks](https://explained.ai/rnn/index.html) and notebook [prep.ipynb](prep.ipynb) should be run before this notebook as it needs files: `data/X.pkl` and `data/y.pkl`.\n",
    "\n",
    "Instead of processing batch one record at a time from time 1 to time len(word), process all time steps t across all batch records at once, then proceed to time step (char index) t+1.  This allows us to vectorize and perform each time step in parallel.  We effectively remove a loop.\n",
    "\n",
    "But, it means we must pad to have same length in batch. We pad on left so the zero vectors are ignored to get same answer as record-by-record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.set_printoptions(precision=2, suppress=True, linewidth=3000, threshold=20000)\n",
    "from typing import Sequence\n",
    "\n",
    "!if ! test -f support.py; then wget https://raw.githubusercontent.com/parrt/ml-articles/master/rnn/notebooks/support.py; fi\n",
    "\n",
    "from support import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/X.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "with open('data/y.pkl', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TESTING SUBSAMPLE\n",
    "idx = list(np.random.randint(0,len(X),size=2000))\n",
    "X = np.array(X)[idx].tolist()\n",
    "y = np.array(y)[idx].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split out validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    max_len = 0\n",
    "    for x in X:\n",
    "        max_len = max(max_len, len(x))\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_matrix(X, max_len, vocab, verbose=False):\n",
    "    X_onehot = torch.zeros(len(X),max_len,len(vocab), dtype=torch.float64)\n",
    "    for i,x in enumerate(X):\n",
    "        pad = max_len - len(x)\n",
    "        for j,c in enumerate(x):\n",
    "            X_onehot[i, j+pad, ctoi[c]] = 1\n",
    "        if verbose: print(x); print(X_onehot[i].T, \"\\n\")\n",
    "    return X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X:Sequence[Sequence], max_len:int, vocab:dict):\n",
    "    \"Cut-n-paste from body of training for use with metrics\"\n",
    "    X_onehot = onehot_matrix(X, max_len, vocab)\n",
    "    h = torch.zeros(nhidden, len(X), dtype=torch.float64, requires_grad=False)\n",
    "    for j in range(max_len):\n",
    "        x_step_t = X_onehot[:,j].T\n",
    "        h = W.mm(h) + U.mm(x_step_t)\n",
    "        h = torch.tanh(h)        \n",
    "    o = V.mm(h)\n",
    "    o = o.T # make it batch_size x nclasses\n",
    "    o = softmax(o)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just some matrices. First, set up hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ctoi = getvocab(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with trivial data set\n",
    "\n",
    "Set TESTING=True to test vs full X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING = False\n",
    "\n",
    "nhidden = 100\n",
    "batch_size = 32\n",
    "\n",
    "if TESTING:\n",
    "    nhidden = 2\n",
    "    batch_size = 2\n",
    "\n",
    "    X_train = [['a','b'],['c','d','e'], # batch 1\n",
    "               ['f'],['c','a'], # batch 2\n",
    "               ['e']] # strip\n",
    "    y_train = [0,2,1,1,2]\n",
    "\n",
    "    X_valid = X_train\n",
    "    y_valid = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,688 training records, batch size 32, 29 features (chars), 18 target languages, state is 100-vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "n = len(X_train)\n",
    "\n",
    "nbatches = n // batch_size\n",
    "n = nbatches * batch_size\n",
    "X_train = X_train[0:n]\n",
    "y_train = y_train[0:n]\n",
    "vocab, ctoi = getvocab(X_train)\n",
    "max_len = get_max_len(X_train)\n",
    "nfeatures = len(vocab)\n",
    "nclasses = len(torch.unique(torch.tensor(y_train)))\n",
    "\n",
    "print(f\"{n:,d} training records, batch size {batch_size}, {nfeatures} features (chars), {nclasses} target languages, state is {nhidden}-vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['g', 'r', 'i', 'g', 'g', 's'], ['m', 'u', 'k', 'k', 'e']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_onehot = onehot_matrix(X_train, max_len, vocab, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With verbose and trivial X_train we get:\n",
    "\n",
    "```\n",
    "tensor([[[0., 0., 0., 0., 0., 0.],\n",
    "         [1., 0., 0., 0., 0., 0.],\n",
    "         [0., 1., 0., 0., 0., 0.]],\n",
    "\n",
    "        [[0., 0., 1., 0., 0., 0.],\n",
    "         [0., 0., 0., 1., 0., 0.],\n",
    "         [0., 0., 0., 0., 1., 0.]],\n",
    "\n",
    "        [[0., 0., 0., 0., 0., 0.],\n",
    "         [0., 0., 0., 0., 0., 0.],\n",
    "         [0., 0., 0., 0., 0., 1.]],\n",
    "\n",
    "        [[0., 0., 0., 0., 0., 0.],\n",
    "         [0., 0., 1., 0., 0., 0.],\n",
    "         [1., 0., 0., 0., 0., 0.]]], dtype=torch.float64)\n",
    "```\n",
    "\n",
    "With `X_onehot.shape` = [4, 3, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using vectorized minibatch SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/parrt/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1 accum loss  2.0357 accur 0.615 | train loss  1.2107 accur 0.680 | valid loss  1.4778 accur 0.649\n",
      "Epoch:   2 accum loss  1.1679 accur 0.691 | train loss  0.9325 accur 0.743 | valid loss  1.2151 accur 0.690\n",
      "Epoch:   3 accum loss  0.9820 accur 0.728 | train loss  0.9184 accur 0.747 | valid loss  1.2522 accur 0.693\n",
      "Epoch:   4 accum loss  0.8912 accur 0.747 | train loss  0.8016 accur 0.770 | valid loss  1.1559 accur 0.710\n",
      "Epoch:   5 accum loss  0.8431 accur 0.756 | train loss  0.8055 accur 0.770 | valid loss  1.1834 accur 0.708\n",
      "Epoch:   6 accum loss  0.8054 accur 0.765 | train loss  0.7569 accur 0.791 | valid loss  1.1343 accur 0.726\n",
      "Epoch:   7 accum loss  0.7644 accur 0.775 | train loss  0.7283 accur 0.795 | valid loss  1.1561 accur 0.718\n",
      "Epoch:   8 accum loss  0.7406 accur 0.781 | train loss  0.7138 accur 0.789 | valid loss  1.1616 accur 0.711\n",
      "Epoch:   9 accum loss  0.7129 accur 0.788 | train loss  0.6803 accur 0.800 | valid loss  1.1655 accur 0.724\n",
      "Epoch:  10 accum loss  0.6834 accur 0.794 | train loss  0.6463 accur 0.810 | valid loss  1.1208 accur 0.731\n",
      "Epoch:  11 accum loss  0.6708 accur 0.795 | train loss  0.6261 accur 0.812 | valid loss  1.1416 accur 0.720\n",
      "Epoch:  12 accum loss  0.6558 accur 0.799 | train loss  0.6653 accur 0.798 | valid loss  1.1973 accur 0.712\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 29s, sys: 37.2 s, total: 3min 6s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#torch.manual_seed(0) # SET SEED FOR TESTING\n",
    "W = torch.eye(nhidden,    nhidden,   dtype=torch.float64, requires_grad=True)\n",
    "U = torch.randn(nhidden,  nfeatures, dtype=torch.float64, requires_grad=True) # embed one-hot char vec\n",
    "V = torch.randn(nclasses, nhidden,   dtype=torch.float64, requires_grad=True) # take RNN output (h) and predict target\n",
    "\n",
    "optimizer = torch.optim.Adam([W,U,V], lr=0.005, weight_decay=0.0)\n",
    "\n",
    "history = []\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs+1):\n",
    "#     print(f\"EPOCH {epoch}\")\n",
    "    epoch_training_loss = 0.0\n",
    "    epoch_training_accur = 0.0\n",
    "    total = 0\n",
    "    for p in range(0, n, batch_size):  # do one epoch\n",
    "        loss = 0\n",
    "        batch_X = X_train[p:p+batch_size]\n",
    "        batch_y = y_train[p:p+batch_size]\n",
    "        batch_X_onehot = onehot_matrix(batch_X, max_len, vocab)\n",
    "        H = torch.zeros(nhidden, batch_size, dtype=torch.float64, requires_grad=False)\n",
    "        for t in range(max_len):\n",
    "            x_step_t = batch_X_onehot[:,t].T # make it len(vocab) x batch_size\n",
    "            H = W.mm(H) + U.mm(x_step_t)\n",
    "            H = torch.tanh(H)\n",
    "        o = V.mm(H)\n",
    "        o = o.T # make it batch_size x nclasses\n",
    "        o = softmax(o)\n",
    "        loss = cross_entropy(o, batch_y)\n",
    "#         print(loss.item())\n",
    "        correct = torch.argmax(o, dim=1)==batch_y\n",
    "        epoch_training_accur += torch.sum(correct)\n",
    "        total += len(batch_y)\n",
    "\n",
    "        # update matrices based upon loss computed from a batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # autograd computes U.grad, M.grad, ...\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_training_loss += loss.detach().item()\n",
    "\n",
    "    epoch_training_loss /= nbatches\n",
    "    epoch_training_accur /= n\n",
    "#     print(f\"Epoch {epoch:3d} training loss {epoch_training_loss:7.4f} accur {epoch_training_accur:7.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        o = forward(X_train, max_len, vocab)#, apply_softmax=False)\n",
    "        train_loss = cross_entropy(o, y_train).item()\n",
    "        correct = torch.argmax(o, dim=1).detach()==torch.tensor(y_train)\n",
    "        train_accur = torch.sum(correct) / float(len(X_train))\n",
    "\n",
    "        o = forward(X_valid, max_len, vocab)\n",
    "        valid_loss = cross_entropy(o, y_valid).item()\n",
    "        correct = torch.argmax(o, dim=1).detach()==torch.tensor(y_valid)\n",
    "        valid_accur = torch.sum(correct) / float(len(X_valid))\n",
    "\n",
    "        history.append((train_loss, valid_loss))\n",
    "        print(f\"Epoch: {epoch:3d} accum loss {epoch_training_loss:7.4f} accur {epoch_training_accur:4.3f} | train loss {train_loss:7.4f} accur {train_accur:4.3f} | valid loss {valid_loss:7.4f} accur {valid_accur:4.3f}\")\n",
    "\n",
    "history = torch.tensor(history)\n",
    "plot_history(history, yrange=(0,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing on 80% training from full data set:\n",
    "\n",
    "```\n",
    "CPU times: user 40.3 s, sys: 749 ms, total: 41 s\n",
    "Wall time: 41 s\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
